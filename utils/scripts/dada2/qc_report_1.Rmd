---
title: "From 16S Amplicon Raw Data to ASVs (Amplicon Sequence Variants)"
author: "IMC Bioinformatics"
date: "`r format(Sys.time(), '%d %B, %Y')`"
params:
   rmd: "qc_report.Rmd"
   quality: ""
   out_dir: ""
   fwd_suffix: ""
   rev_suffix: ""
   primer_removal: ""
   primer_investigation: ""
   Nread: ""
output:
html_document:
    theme: flatly
    highlight: tango
    toc: yes
    number_sections: yes
    toc_depth: 4
    toc_float:
      collapsed: no
    smooth_scroll: yes
---

<br>
<br>

```{r needed packages, message=F,include=F, warning=F}
suppressMessages(library(limma))
suppressMessages(library(tidyverse))
suppressMessages(library(ggplot2))
suppressMessages(library(ggpubr))
suppressMessages(library(plotly))
suppressMessages(library(waterfalls))
suppressMessages(library(DT))
suppressMessages(library(htmlwidgets))
```


```{r needed files, echo=F}
quality <- params$quality
out_dir <- params$out_dir
fwd_suffix <- params$fwd_suffix
rev_suffix <- params$rev_suffix
primer_removal<- params$primer_removal
primer_investigation <- params$primer_investigation
Nread <- params$Nread



#print(paste("quality = ", quality, "\n"))
#print(paste("out_dir = ", out_dir, "\n"))
#print(paste("Forward reads file  = ", fwd_suffix, "\n"))
#print(paste("Reverse reads file  = ", rev_suffix, "\n"))
#print(paste("primer-removal  = ", primer_removal, "\n"))
#print(paste("Nread file = ",Nread, "\n"))

```

# **Investigating reads**

<br>

## Overall read quality plots {.tabset .tabset-fade}

<br>

The overall read quality plots offer a comprehensive assessment of the sequencing run's data integrity, highlighting raw and proce
ssed read quality. The plots display quality scores (Y-axis) against read positions (X-axis), showing a
typical trend where quality decreases towards the end of the reads. The left panel represents forward reads quality and The right 
panel illustrates reverse reads quality aggregated for all samples. In gray-scale is a heat map of the frequency of each quality
score at each base position is shown. The mean quality score at each position is shown by the green line, and the quartiles of the
 quality score distribution by the orange lines. The red line shows the scaled proportion of reads that extend to at least that
position (this is more useful for other sequencing technologies, as Illumina reads are typically all the same length, hence a flat
 red line will be expected).

<br>

### Read quality raw 

<br>

```{r,results='asis', echo=F}

files <- list.files(path = quality, pattern = "raw", full.names = TRUE)

for (f in files) {
  cat(paste0("![](", f, "){width=50%}"))
 }

```

<br>
<br>
<br>
<br>
<br>


### Read Quality after read quality trimming

<br>

```{r, results='asis',echo=F}

files <- list.files(path = quality, pattern = "afterQC", full.names =TRUE)

for (f in files) {
  cat(paste0("![](", f, "){width=50%}"))
 }
```

<br>
<br>
<br>
<br>
<br>

### Read Quality after read error rate filtering

<br>

```{r, results='asis', echo=F}

files <- list.files(path = quality, pattern = "afterdada2", full.names =TRUE)

for (f in files) {
  cat(paste0("![](", f, "){width=50%}"))
 }
```

<br>
<br>
<br>
<br>
<br>

## Read length distribution for all samples in the run {.tabset .tabset-fade}

<br>

Read length distribution is shown in this plot for all reads in all samples after each step. This shows how removing primer (if applicable), quality trimming, and error rate filtering affects the length of reads during the process. The Y-axis represents the abundance of reads stacked per sample, while the X-axis shows the read lengths in base pairs (bp).

<br>

**You can use the range slider at the bottom of plot to zoom in or zoom out, hover over bars to know more about the reads length and count. Samples listed on the right panel can be excluded and included by clicking on them. Reads with counts less than 200 are 
removed for improving the visualization.**

<br>
<br>

```{r plotly, echo=F,fig.width=10,fig.height=5}

in_dir<-paste0(out_dir,"/seqkit_samples")



forward_read_suffix <- fwd_suffix
reverse_read_suffix <- rev_suffix
primer_removal <- primer_removal
primer_investigation<-primer_investigation

# Convert the value to logical if necessary
if (is.character(primer_removal)) {
  if (tolower(primer_removal) == "true") {
    primer_removal <- TRUE
  } else if (tolower(primer_removal) == "false") {
    primer_removal <- FALSE
  }
}

# Convert the valuTRUE# Convert the value to logical if necessary
if (is.character(primer_investigation)) {
  if (tolower(primer_investigation) == "true") {
    primer_investigation <- TRUE
  } else if (tolower(primer_investigation) == "false") {
    primer_investigation <- FALSE
  }
}

##reading files in and save them as objects
if(primer_removal== TRUE & primer_investigation==TRUE){
  object_names <- list.files(in_dir, pattern = paste0(forward_read_suffix,"|",reverse_read_suffix),full.names = T)
} else if (primer_removal== TRUE & primer_investigation==FALSE) {
  object_names <- list.files(in_dir, pattern = paste0(forward_read_suffix,"|",reverse_read_suffix),full.names = T)
  object_names=object_names[!grepl(pattern = "primerRMV",x = object_names)]
  names<-unique(sapply(strsplit(object_names,split=paste0(forward_read_suffix,"|",reverse_read_suffix)),`[`,1))
}

for (i in 1:length(object_names)) {
  # Read in the object
  my_data <- read.table(object_names[i],header = F)
  # Save the updated object
  assign(x=gsub(".txt","",basename(object_names[i])),value = my_data)
  
}


## fixing raw files
raw_objects <- ls(pattern = "raw")

for (i in raw_objects){
  # Read in the object
  my_data <- get(i)
  if (nrow(my_data) == 1){ #this for times that primers are already removed from raw reads and they are not the same length anymore
    my_data <- data.frame(
      V1 = seq_along(1:my_data$V1),
      V2 = c(rep(x = 0, times = my_data$V1-1), rep(my_data$V2, times = 1))) # Add missing closing parentheses
    #Save the updated object
    assign(i, value = my_data)
  }
}



object_names <- ls(pattern = paste0(forward_read_suffix,"|",reverse_read_suffix))


#### Loop over each file and change the column names and save them as a new object each
for (i in object_names) {
  # Read in the object
  my_data <- get(i)
  
  # Print the current column names
  #print(colnames(my_data))
  
  # Change the column names
  colnames(my_data) <- c("read_length", "num_reads")
  
  # Print the new column names
  #print(colnames(my_data))
  
  # Save the updated object
  assign(i,value = my_data)
}



#add two columns of readtype and filetype to all object files based on a name

# Conditional logic
if (primer_removal == TRUE & primer_investigation==TRUE) {
  names <- c("raw", "dada2", "primerRMV", "cutadapt")
} else {
  names <- c("raw", "dada2", "cutadapt")
}


# loop over the selected objects and add columns to them
for (i in names){
  objs <- ls(pattern = i)
  for (j in objs){
    x <- get(j)
    x <- cbind(x, filetype = i)
    colnames(x)
    assign(j, x)
  }
}


reads <- c(forward_read_suffix,reverse_read_suffix)


# loop over the selected objects and add columns to them
for (i in reads){
  objs <- ls(pattern = i)
  for (j in objs){
    x <- get(j)
    x <- cbind(x, readtype = i)
    colnames(x)
    assign(j, x)
  }
}




# Loop through the list of object names and combine them using rbind
for (i in names){
  obj_list=ls(pattern = i)
  combined_data <- data.frame() # Create an empty data frame to store the combined data
  for (j in obj_list) {
    obj <- get(j)
    if (is.data.frame(obj)) {
      combined_data <- rbind(combined_data, obj)
      assign(x = paste0("combined_",i), combined_data)
    }
  }
}


rm(combined_data)

# Loop through each file and make column filetype a factor and add a column as sample_name
for (file in ls(pattern = "combined_")) {
  # Read in the file
  data <- get(file)
  
  if (primer_removal == TRUE) {
    # Convert the desired column to a factor
    data$filetype <- factor(data$filetype,levels = c("raw","primerRMV","cutadapt","dada2"))
  } else {
    # Convert the desired column to a factor
    data$filetype <- factor(data$filetype,levels = c("raw","cutadapt","dada2"))
  }
  
  # Add a new column
  name <- strsplit2(file,split = "combined_")[2]
  data$sample_name <- name
  
  # Save the modified file back to disk
  assign(value = data, x = file)
}



final_data <- data.frame() # Create an empty data frame to store the combined data


files=ls(pattern = "combined_")

# Loop through the list of combined sample object names and combine them using rbind
for (i in files){
  obj <- get(i)
  if (is.data.frame(obj)) {
    final_data <- rbind(final_data, obj)
  }
}


final_data <- final_data %>%
  mutate(readtype = gsub(forward_read_suffix, "R1", readtype),
         readtype = gsub(reverse_read_suffix, "R2", readtype),
         filetype = gsub("raw","Raw reads",filetype),
         filetype = gsub("primerRMV","After Primer Removal",filetype),
         filetype = gsub("cutadapt","After Quality Trimming",filetype),
         filetype = gsub("dada2","After DADA2",filetype)) %>%
         filter(., num_reads > 200)



final_data$filetype <- factor(final_data$filetype,levels = c("Raw reads","After Primer Removal","After Quality Trimming","After DADA2"))

###Forward

p <- ggplot(final_data %>% filter(num_reads > 0 & readtype=="R1"), aes(x = read_length, y = num_reads, fill = sample_name)) +
  geom_col(width = 1) +
  theme_bw() +
  labs(title = "All the forward reads in all samples length distribution") +
  xlab(NULL) +
  ylab(NULL) +
  theme(legend.position = "right")





if (primer_removal == TRUE) {
  # Convert to plotly and enable zooming
  plotly_p <- p +
    facet_wrap(~filetype, ncol = 4)
  plotly_p <- plotly_p %>% plotly::ggplotly() %>%  
    layout(xaxis = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           xaxis2 = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           xaxis3 = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           xaxis4 = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           yaxis = list(fixedrange = FALSE))
  } else {
  # Convert to plotly and enable zooming
  plotly_p <- p +
    facet_wrap(~filetype, ncol = 3) 
  plotly_p <- plotly_p %>% plotly::ggplotly() %>%
    layout(xaxis = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           xaxis2 = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           xaxis3 = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           yaxis = list(fixedrange = FALSE))
  }



# Show the plot
plotly_p



###Reverse

p <- ggplot(final_data %>% filter(num_reads > 0 & readtype=="R2"), aes(x = read_length, y = num_reads, fill = sample_name)) +
  geom_col(width = 1) +
  theme_bw() +
  labs(title = "All the reverse reads in all samples length distribution") +
  xlab(NULL) +
  ylab(NULL) +
  theme(legend.position = "right")





if (primer_removal == TRUE) {
  # Convert to plotly and enable zooming
  plotly_p <- p +
    facet_wrap(~filetype, ncol = 4)
  plotly_p <- plotly_p %>% plotly::ggplotly() %>%
    layout(xaxis = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           xaxis2 = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           xaxis3 = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           xaxis4 = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           yaxis = list(fixedrange = FALSE))
  } else {
  # Convert to plotly and enable zooming
  plotly_p <- p +
    facet_wrap(~filetype, ncol = 3)
  plotly_p <- plotly_p %>% plotly::ggplotly() %>%
    layout(xaxis = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           xaxis2 = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           xaxis3 = list(rangeslider = list(visible = TRUE), rangemode = "normal"),
           yaxis = list(fixedrange = FALSE))
  }



# Show the plot
plotly_p

```

<br>
<br>
<br>
<br>
<br>

```{r,echo=F,messages=FALSE, warning=FALSE}

reads<-read.csv(Nread,sep="\t")

```

## Reads count change throughout the dada2 pipeline in all samples

<br>

This plot provides a step-by-step overview of the changes in read counts throughout the DADA2 pipeline for all samples. It illustr
ates how many sequencing reads are discarded at each stage of the processing workflow, from the initial raw data to the
final remained cleaned data. Each step, including quality trimming, filtering, denoising, merging, and chimera removal, is shown w
ith the corresponding number of reads lost. The final bar indicates the total number of high-quality reads remaining after all
processing steps.

<br>


```{r table merge,echo=F,messages=FALSE, warning=FALSE,include=T,fig.width=11,fig.height=7}
reads1<-reads

colnames(reads1)[1:7]<-c("Sample", "Raw", "not-Quality_Trimmed", "not-Filtered", "Denoised", "Merged","Cleaned")

reads1 <- reads1 %>% mutate_all(~ifelse(is.na(.), 0, .))

read_loss<-data.frame(step=names(colSums(reads1[,-c(1, 8)])),count=colSums(reads1[,-c(1, 8)]))

read_loss$step<- c("Raw", "Quality_Trimmed", "Filtered", "not-Denoised", "not-Merged","Chimeric")

# Create a color palette for the bars (you can customize these colors)
colors <- c("Raw" = "#f5f0e1", "Quality_Trimmed" = "#ff6e40",
            "Filtered" = "#ff6e40", "not-Denoised" = "#ff6e40",
            "not-Merged" = "#ff6e40","Chimeric" = "#ff6e40")



# Create a new data frame with the "step" and "loss" columns
new_data <- data.frame(
  step = read_loss$step,
  loss = c(read_loss$count[1],
           diff(read_loss$count)[1:5])) %>%
mutate(label = paste(step, "\n(n=", loss, ")"))

waterfall(new_data, calc_total = TRUE,
          fill_by_sign = F,
          rect_text_size = 1.5,
          fill_colours = colors,
          total_rect_color = "#ffc13b",
          total_rect_text_color = "black")+
  theme_bw()+xlab("Read Counts")+ylab("Processing steps")+ggtitle("Read count change in each step")+
  theme(axis.text.x = element_text(angle = 45, size = 14, colour = "black",  hjust = 1, face= "bold"), 
        axis.title.y = element_text(size = 14, face = "bold"), 
        legend.title = element_text(size = 16, face = "bold"),
        axis.title.x = element_text(size = 12, face = "bold"),
        legend.text = element_text(size = 14, face = "bold", colour = "black"),
        legend.position = "bottom",
        axis.text.y = element_text(colour = "black", size = 14, face = "bold"),
        plot.title = element_text(size=14,face="bold"),
        plot.caption = element_text(hjust = 0,vjust=0.5,size = 12, face= "bold", colour = "red"),
        panel.background = element_blank(),
        panel.border =element_rect(fill = NA, color = "black"), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black"))
  


htmltools::HTML("<br>")
htmltools::HTML("<br>")


reads1[,8]<-data.frame(reads1$Cleaned/reads1$Raw)*100
colnames(reads1)[8]<-"Clean_Reads_Percent"
reads1[,8]<-round(reads1[,8],digits = 2)



datatable(reads1, 
          rownames= FALSE,
          filter = 'top',
          extensions = 'Buttons',
          options = list(scrollX = TRUE,
                         pageLength = 5,
                         dom = 'Blfrtip',
                         buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
                         rownames = F),
                         caption = htmltools::tags$caption(style = 'caption-side: bottom; text-align: left;',
                         htmltools::em('Tracking Read Counts Across the DADA2 Pipeline:'), htmltools::br(), 
                         htmltools::em('Raw: Initial number of reads in each sample.'), htmltools::br(),
                         htmltools::em('not-Quality_Trimmed: Reads left after primer removal (if applicable) and quality trimming prior to DADA2 processing.'), htmltools::br(),
                         htmltools::em('not-Filtered: Reads left after eliminating sequences with ambiguous bases, high error rates, and short length.'), htmltools::br(),
                         htmltools::em('Denoised: Reads left with high quality and error-corrected sequences.'), htmltools::br(),
                         htmltools::em('Merged: Reads left after removal of singletons and unmerged forward and reverse read pairs.'), htmltools::br(),
                         htmltools::em('Cleaned: Reads left after eliminating chimeric sequences,artifact sequences created during PCR due to partially extended strands binding to similar but different sequences.'), htmltools::br(),
                         htmltools::em('If there is a sample called undetermined, it contains the reads that could not be assigned to any samples.')))


```

<br>
<br>
<br>
<br>
<br>

## Distribution of initial and final read counts

<br>

This plot compares the distribution of read counts at the beginning and end of the data processing pipeline for all samples. The l
eft panel shows the initial distribution of raw reads and the right panel illustrates the final distribution of clean reads
after all the steps of trimming, filtering, denoising, merging, and chimera removal have been applied. Each bar represents the num
ber of samples falling within specific read count ranges.

<br>

```{r boxplot,echo=F,messages=FALSE, warning=FALSE,results = FALSE,fig.width=11,fig.height=7}

reads2<-data.frame(rep("Starting number of reads",times=nrow(reads1)),reads1$Raw)
colnames(reads2)<-c("Var","value")


reads3<-data.frame(rep("Finishing number of reads",times=nrow(reads1)),reads1$Cleaned)
colnames(reads3)<-c("Var","value")


n=max(reads2$value)/10

# Determine max bin count
max_count <- max(hist(reads2$value, breaks=seq(0, max(reads2$value), by=n), plot=FALSE)$counts)

A<-ggplot(reads2, aes(x=value)) + 
  geom_histogram(color="black", fill="#E69F00",binwidth = n,boundary=0)+ #boundary start starts the bin from zero
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, size = 12, colour = "black",  hjust = 1, face= "bold"),
        axis.title.y = element_text(size = 12, face = "bold"), legend.title = element_text(size = 16, face = "bold"),
        axis.title.x = element_text(size = 12, face = "bold"),
        legend.text = element_text(size = 12, face = "bold", colour = "black"),
        axis.text.y = element_text(colour = "black", size = 12, face = "bold"),
        plot.title = element_text(size=14,face="bold"),
        plot.caption = element_text(hjust = 0,vjust=1.5,size = 12, face = "bold", colour = "red"),
        legend.position = "None")+xlab("Raw reads (count)")+ylab("Sample count")+
  ggtitle("Starting number of reads distribution")+
  theme(panel.background = element_blank(),
        panel.border =element_rect(fill = NA, color = "black"), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black"))+
  # update: adds counts above bars
  stat_bin(binwidth = n,boundary = 0, aes(label=ifelse(..count.. > 0, ..count.., "")),geom="text",vjust=-0.9,hjust=0.5)+ 
coord_cartesian(ylim=c(0, max_count + 30))#+labs(caption="Binwidth is 5.")



n=max(reads3$value)/10

# Determine max bin count
max_count <- max(hist(reads3$value, breaks=seq(0, max(reads3$value), by=n), plot=FALSE)$counts)

B<-ggplot(reads3, aes(x=value)) +
  geom_histogram(color="black", fill="#E69F00",binwidth = n,boundary=0)+ #boundary start starts the bin from zero
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, size = 12, colour = "black",  hjust = 1, face= "bold"),
        axis.title.y = element_text(size = 12, face = "bold"), legend.title = element_text(size = 16, face = "bold"),
        axis.title.x = element_text(size = 12, face = "bold"),
        legend.text = element_text(size = 12, face = "bold", colour = "black"),
        axis.text.y = element_text(colour = "black", size = 12, face = "bold"),
        plot.title = element_text(size=14,face="bold"),
        plot.caption = element_text(hjust = 0,vjust=1.5,size = 12, face = "bold", colour = "red"),
        legend.position = "None")+xlab("Clean reads (count)")+ylab("Sample count")+
  ggtitle("Final number of clean reads distribution")+
  theme(panel.background = element_blank(),
        panel.border =element_rect(fill = NA, color = "black"), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour ="black"))+
  # update: adds counts above bars
  stat_bin(binwidth = n,boundary = 0, aes(label=ifelse(..count.. > 0, ..count.., "")),geom="text",vjust=-0.9,hjust=0.5)+ 
coord_cartesian(ylim=c(0, max_count + 30))#+labs(caption="Binwidth is 5.")


ggarrange(A,B)

```

<div Class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
